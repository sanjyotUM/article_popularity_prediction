{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "pd.set_option('max_colwidth', 300)\n",
    "pd.set_option('max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all parts of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_path = '../Datasets/Headlines/guardian_main_model/guardian_train.csv'\n",
    "train_labels = '../Datasets/Headlines/guardian_popularity_measures/guardian_train_popularity.csv'\n",
    "train_headline_path = '../Datasets/Headlines/guardian_headlines/headlines-final.csv'\n",
    "\n",
    "test_feature_path = '../Datasets/Headlines/guardian_main_model/guardian_test.csv'\n",
    "test_labels = '../Datasets/Headlines/guardian_popularity_measures/guardian_test_popularity.csv'\n",
    "test_headline_path = '../Datasets/Headlines/guardian_headlines/headlines_test-final_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_headline_file(path):\n",
    "    return pd.read_csv(\n",
    "        path, \n",
    "        sep='|', \n",
    "        names=['article_id', 'section', 'publish_date', 'title']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(ft_path, ll_path, hl_path):\n",
    "    ft = pd.read_csv(ft_path)\n",
    "    ll = pd.read_csv(ll_path)\n",
    "    hl = read_headline_file(hl_path)\n",
    "    \n",
    "    df = (\n",
    "        ft\n",
    "        .merge(ll, on=['article_id'])\n",
    "        .merge(hl, on=['article_id'])\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combine_data(train_feature_path, train_labels, train_headline_path)\n",
    "test = combine_data(test_feature_path, test_labels, test_headline_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9814, 224)\n",
      "(10753, 224)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Mashable Headlines data for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mash_data_path = '../Datasets/OnlineNewsPopularity-Mashable/mashable_all_features_with_text.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl = pd.read_csv(mash_data_path)[['title', 'shares']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>26340</td>\n",
       "      <td>What We Learned From Apple WWDC 2014</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26341</td>\n",
       "      <td>Artist Prints Van Gogh's Ear From Family DNA</td>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26342</td>\n",
       "      <td>15 Gorgeous Vacation Spots Proving Heaven Is a Place on Earth</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26343</td>\n",
       "      <td>This Is the Man Who Made Grumpy Cat Rich</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26344</td>\n",
       "      <td>'Security Concerns' Halt Bowe Bergdahl's Hometown Celebration</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26345</td>\n",
       "      <td>'Bricksy' Reimagines Banksy's Artwork in Lego Form</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26346</td>\n",
       "      <td>Yes, You Should Care About Reaching Profitability</td>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26347</td>\n",
       "      <td>An 'Honest' Take on Your Candy Crush Addiction</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26348</td>\n",
       "      <td>Chinese State Media: Google, Facebook, Yahoo Are U.S. 'Pawns'</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26349</td>\n",
       "      <td>The Undeniable Comfort of Dogs Goes on the Road</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26350</td>\n",
       "      <td>Concept Video Shows Google Glass Used as a Targeting Display</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26351</td>\n",
       "      <td>What Do Consumer Privacy Concerns Mean for Entrepreneurs?</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26352</td>\n",
       "      <td>Young Couple Missing in Afghanistan Surfaces in Videos Asking U.S. for Help</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26353</td>\n",
       "      <td>Late-Night Reveler Keeps Train Riders Awake With Sing-Along</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26354</td>\n",
       "      <td>E3 2014: Expect Lots of Promising Software</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26355</td>\n",
       "      <td>Unplanned Cameo Surprises Seth MacFarlane in His Own Movie</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26356</td>\n",
       "      <td>Fab CEO: Rumors That We're Shutting Down Are 'Bullsh*t Hate'</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26357</td>\n",
       "      <td>5 Facts You Didn't Know About Google</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26358</td>\n",
       "      <td>There's Already a 'Flappy Bird' Clone in Apple's New Swift Language</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26359</td>\n",
       "      <td>Windows Users Have 2 Weeks to Root Out 'Gameover Zeus'</td>\n",
       "      <td>6300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             title  \\\n",
       "26340                                         What We Learned From Apple WWDC 2014   \n",
       "26341                                 Artist Prints Van Gogh's Ear From Family DNA   \n",
       "26342                15 Gorgeous Vacation Spots Proving Heaven Is a Place on Earth   \n",
       "26343                                     This Is the Man Who Made Grumpy Cat Rich   \n",
       "26344                'Security Concerns' Halt Bowe Bergdahl's Hometown Celebration   \n",
       "26345                           'Bricksy' Reimagines Banksy's Artwork in Lego Form   \n",
       "26346                            Yes, You Should Care About Reaching Profitability   \n",
       "26347                               An 'Honest' Take on Your Candy Crush Addiction   \n",
       "26348                Chinese State Media: Google, Facebook, Yahoo Are U.S. 'Pawns'   \n",
       "26349                              The Undeniable Comfort of Dogs Goes on the Road   \n",
       "26350                 Concept Video Shows Google Glass Used as a Targeting Display   \n",
       "26351                    What Do Consumer Privacy Concerns Mean for Entrepreneurs?   \n",
       "26352  Young Couple Missing in Afghanistan Surfaces in Videos Asking U.S. for Help   \n",
       "26353                  Late-Night Reveler Keeps Train Riders Awake With Sing-Along   \n",
       "26354                                   E3 2014: Expect Lots of Promising Software   \n",
       "26355                   Unplanned Cameo Surprises Seth MacFarlane in His Own Movie   \n",
       "26356                 Fab CEO: Rumors That We're Shutting Down Are 'Bullsh*t Hate'   \n",
       "26357                                         5 Facts You Didn't Know About Google   \n",
       "26358          There's Already a 'Flappy Bird' Clone in Apple's New Swift Language   \n",
       "26359                       Windows Users Have 2 Weeks to Root Out 'Gameover Zeus'   \n",
       "\n",
       "       shares  \n",
       "26340     400  \n",
       "26341    7700  \n",
       "26342    1900  \n",
       "26343    1000  \n",
       "26344     935  \n",
       "26345    1400  \n",
       "26346    4300  \n",
       "26347    1400  \n",
       "26348    2300  \n",
       "26349    1500  \n",
       "26350    1200  \n",
       "26351    1100  \n",
       "26352    1200  \n",
       "26353    1200  \n",
       "26354    1000  \n",
       "26355    9500  \n",
       "26356    1000  \n",
       "26357     883  \n",
       "26358     895  \n",
       "26359    6300  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = random.randint(0, len(hl)-30)\n",
    "hl.iloc[ind:ind+20, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Feature engineering\n",
    "Syntactic features:\n",
    "1. Total tokens\n",
    "1. Average token length\n",
    "1. Ratio of title cased tokens\n",
    "1. Ratio of upper cased tokens\n",
    "1. Presence of exclamation\n",
    "1. Presence of question mark\n",
    "1. Presence of quote marks\n",
    "\n",
    "\n",
    "\n",
    "Symantic features:\n",
    "1. Three consecutive nouns\n",
    "1. Noun percentage\n",
    "1. Verb percentage\n",
    "1. Proper noun percentage\n",
    "1. Adverb percentage\n",
    "1. Adjective percentage\n",
    "1. Count of non stop-words\n",
    "\n",
    "\n",
    "Smarter features:\n",
    "1. Action words (do, stop, fight etc.\n",
    "1. Urgency words (immediate, now, time etc)\n",
    "1. Pantheon, Wikipedia page view features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syntactic_features(df, hl_col, nlp):\n",
    "    \n",
    "    def total_tokens(doc):\n",
    "        return len(doc)\n",
    "    \n",
    "    def avg_token_len(doc):\n",
    "        return np.mean(np.array([len(x) for x in doc]))\n",
    "    \n",
    "    def title_case_tokens(doc):\n",
    "        return len([x for x in doc if x.shape_[0] == 'X'])/len(doc)\n",
    "    \n",
    "    def upper_case_tokens(doc):\n",
    "        return len([x for x in doc if x.text.isupper()])/len(doc)\n",
    "    \n",
    "    def exclamation_token(doc):\n",
    "        return '!' in doc.text\n",
    "    \n",
    "    def question_mark_token(doc):\n",
    "        return '?' in doc.text\n",
    "    \n",
    "    def quote_mark_token(doc):\n",
    "        return (\"'\" in doc.text) or ('\"' in doc.text)\n",
    "    \n",
    "    def master_loop(doc):\n",
    "        return [\n",
    "            total_tokens(doc),\n",
    "            avg_token_len(doc),\n",
    "            title_case_tokens(doc),\n",
    "            upper_case_tokens(doc),\n",
    "            exclamation_token(doc),\n",
    "            question_mark_token(doc),\n",
    "            quote_mark_token(doc)\n",
    "        ]\n",
    "        \n",
    "    ndf = (\n",
    "        df\n",
    "        .assign(\n",
    "            ans_col = lambda x: x.apply(lambda y: master_loop(nlp(y[hl_col])), axis=1),\n",
    "        )\n",
    "        .assign(\n",
    "            total_tokens = lambda x: (x['ans_col'].str[0]),\n",
    "            avg_token_len = lambda x: (x['ans_col'].str[1]),\n",
    "            title_case_tokens = lambda x: (x['ans_col'].str[2]),\n",
    "            upper_case_tokens = lambda x: (x['ans_col'].str[3]),\n",
    "            exclamation_token = lambda x: x['ans_col'].str[4],\n",
    "            question_mark_token = lambda x: x['ans_col'].str[5],\n",
    "            quote_mark_token = lambda x: x['ans_col'].str[6],\n",
    "        )\n",
    "        .drop(['ans_col'], axis=1)\n",
    "    )\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semantic_features(df, hl_col, nlp):\n",
    "    \n",
    "    def get_semantic_features_sentence(doc):\n",
    "        pos_list = [x.pos_ for x in doc]\n",
    "        \n",
    "        def is_noun(pos):\n",
    "                return (pos == 'PROPN') or (pos == 'NOUN')\n",
    "        \n",
    "        def three_consec_nouns(pos_list):\n",
    "            nouns = [is_noun(pos) for pos in pos_list]\n",
    "            for i in range(len(nouns) - 3):\n",
    "                if nouns[i: i+3] == [True, True, True]:\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def noun_percentage(pos_list):\n",
    "            nouns = [is_noun(pos) for pos in pos_list]\n",
    "            return float(np.mean(np.array(nouns)))\n",
    "        \n",
    "        def proper_noun_percentage(pos_list):\n",
    "            return len([x for x in pos_list if x == 'PROPN'])/len(pos_list)\n",
    "        \n",
    "        def verb_percentage(pos_list):\n",
    "            return len([x for x in pos_list if x == 'VERB'])/len(pos_list)\n",
    "        \n",
    "        def adverb_percentage(pos_list):\n",
    "            return len([x for x in pos_list if x == 'ADV'])/len(pos_list)\n",
    "        \n",
    "        def adjective_percentage(pos_list):\n",
    "            return len([x for x in pos_list if x == 'ADJ'])/len(pos_list)\n",
    "        \n",
    "        def interjection(pos_list):\n",
    "            return 'INTJ' in pos_list\n",
    "        \n",
    "        def non_stop_percentage(doc):\n",
    "            return len([x for x in doc if not x.is_stop])/len(doc)\n",
    "        \n",
    "        return [\n",
    "            three_consec_nouns(pos_list), \n",
    "            noun_percentage(pos_list),\n",
    "            proper_noun_percentage(pos_list),\n",
    "            verb_percentage(pos_list), \n",
    "            adverb_percentage(pos_list),\n",
    "            adjective_percentage(pos_list),\n",
    "            interjection(pos_list),\n",
    "            non_stop_percentage(doc)\n",
    "        ]\n",
    "    \n",
    "    ndf = (\n",
    "        df\n",
    "        .assign(\n",
    "            ans_col = lambda x: x.apply(\n",
    "                lambda y: get_semantic_features_sentence(nlp(y[hl_col])), \n",
    "                axis=1\n",
    "            ),\n",
    "        )\n",
    "        .assign(\n",
    "            three_consec_nouns = lambda x: (x['ans_col'].str[0]),\n",
    "            noun_percentage = lambda x: (x['ans_col'].str[1]),\n",
    "            proper_noun_percentage = lambda x: (x['ans_col'].str[2]),\n",
    "            verb_percentage = lambda x: (x['ans_col'].str[3]),\n",
    "            adverb_percentage = lambda x: x['ans_col'].str[4],\n",
    "            adjective_percentage = lambda x: x['ans_col'].str[5],\n",
    "            interjection = lambda x: x['ans_col'].str[6],\n",
    "            non_stop_percentage = lambda x: x['ans_col'].str[7],\n",
    "        )\n",
    "        .drop(['ans_col'], axis=1)\n",
    "    )\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating syntactic features...\n",
      "Calculating semantic features...\n",
      "Joining...\n",
      "Done.\n",
      "CPU times: user 9min 30s, sys: 166 ms, total: 9min 30s\n",
      "Wall time: 9min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Calculating syntactic features...')\n",
    "syntactic_feat = get_syntactic_features(hl, 'title', nlp)\n",
    "print('Calculating semantic features...')\n",
    "semantic_feat = get_semantic_features(hl, 'title', nlp)\n",
    "print('Joining...')\n",
    "all_headline_feat = syntactic_feat.merge(semantic_feat, on=['title', 'shares'])\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_headline_feat.to_csv('../Datasets/OnlineNewsPopularity-Mashable/all_text_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_headline_feat['popular'] = all_headline_feat['shares'] > 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_features = ['total_tokens', 'avg_token_len', 'title_case_tokens', \n",
    "                      'upper_case_tokens', 'exclamation_token', 'question_mark_token', \n",
    "                      'quote_mark_token']\n",
    "semantic_features = ['three_consec_nouns', 'noun_percentage', 'proper_noun_percentage', \n",
    "                     'verb_percentage' ,'adverb_percentage', 'adjective_percentage', \n",
    "                     'interjection', 'non_stop_percentage']\n",
    "\n",
    "final_features = syntactic_features + semantic_features\n",
    "label = 'popular'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_headline_feat[final_features].values\n",
    "y = all_headline_feat[label].values.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=400, \n",
    "    max_depth=5, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjyot/miniconda3/envs/prnn/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.82 s, sys: 12 ms, total: 3.83 s\n",
      "Wall time: 3.83 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=400,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_case_tokens         0.197324\n",
       "proper_noun_percentage    0.115969\n",
       "noun_percentage           0.115965\n",
       "avg_token_len             0.102659\n",
       "non_stop_percentage       0.094424\n",
       "total_tokens              0.075347\n",
       "upper_case_tokens         0.075122\n",
       "verb_percentage           0.062522\n",
       "adjective_percentage      0.062492\n",
       "adverb_percentage         0.051490\n",
       "three_consec_nouns        0.019450\n",
       "question_mark_token       0.008628\n",
       "quote_mark_token          0.008515\n",
       "interjection              0.006021\n",
       "exclamation_token         0.004072\n",
       "dtype: float64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(data=clf.feature_importances_, index=final_features).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5431876328780945 0.526568017487809\n"
     ]
    }
   ],
   "source": [
    "pred_train = clf.predict(X_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(pred_train, y_train)\n",
    "acc_test = accuracy_score(pred_test, y_test)\n",
    "print(acc_train, acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
